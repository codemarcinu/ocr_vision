# Plan UsprawnieÅ„ Systemu Agentowego

**Data utworzenia:** 2026-02-05
**Status:** W trakcie planowania
**Ostatnia aktualizacja:** 2026-02-05

---

## Spis treÅ›ci

1. [Podsumowanie](#podsumowanie)
2. [Obecna architektura](#obecna-architektura)
3. [Zidentyfikowane problemy](#zidentyfikowane-problemy)
4. [Plan implementacji](#plan-implementacji)
   - [Faza 1: Tool Result Memory](#faza-1-tool-result-memory)
   - [Faza 2: Zunifikowana klasyfikacja](#faza-2-zunifikowana-klasyfikacja)
   - [Faza 3: NarzÄ™dzie ask_clarification](#faza-3-narzÄ™dzie-ask_clarification)
   - [Faza 4: Confidence scoring](#faza-4-confidence-scoring)
   - [Faza 5: Multi-tool support](#faza-5-multi-tool-support)
   - [Faza 6: Profil uÅ¼ytkownika](#faza-6-profil-uÅ¼ytkownika)
5. [Harmonogram](#harmonogram)
6. [Metryki sukcesu](#metryki-sukcesu)
7. [Log zmian](#log-zmian)

---

## Podsumowanie

Celem jest usprawnienie systemu agentowego w Second Brain, aby lepiej rozpoznawaÅ‚ intencje uÅ¼ytkownika, eliminowaÅ‚ redundancjÄ™, i wspieraÅ‚ bardziej zÅ‚oÅ¼one scenariusze uÅ¼ycia.

### GÅ‚Ã³wne cele

| # | Cel | Priorytet | Status |
|---|-----|-----------|--------|
| 1 | Zachowanie kontekstu wynikÃ³w narzÄ™dzi | ğŸ”´ Wysoki | âœ… Zaimplementowane |
| 2 | Eliminacja podwÃ³jnej klasyfikacji | ğŸ”´ Wysoki | âœ… Zaimplementowane |
| 3 | Dopytywanie przy niejasnych intencjach | ğŸŸ¡ Åšredni | âœ… Zaimplementowane |
| 4 | Sygnalizowanie pewnoÅ›ci wyboru | ğŸŸ¡ Åšredni | âœ… Zaimplementowane |
| 5 | ObsÅ‚uga wielu narzÄ™dzi w jednym zapytaniu | ğŸŸ¢ Niski | âœ… Zaimplementowane |
| 6 | Personalizacja na podstawie profilu | ğŸŸ¢ Niski | âœ… Zaimplementowane |

---

## Obecna architektura

### Diagram przepÅ‚ywu (AS-IS)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        USER MESSAGE                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚
                                â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    AgentRouter (LLM Call #1)                     â”‚
â”‚  â€¢ System prompt z 10 narzÄ™dziami                               â”‚
â”‚  â€¢ Conversation history (ostatnie 4 msg)                        â”‚
â”‚  â€¢ Output: {"tool": "...", "arguments": {...}}                  â”‚
â”‚  â€¢ Retry logic (max 2)                                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚                       â”‚
            ACTION_TOOLS?              ORCHESTRATOR_TOOLS
            (create_note,              (search_knowledge,
             create_bookmark,           get_spending, etc.)
             summarize_url,                    â”‚
             list_recent)                      â–¼
                    â”‚              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚              â”‚ IntentClassifier      â”‚
                    â”‚              â”‚ (LLM Call #2)         â”‚â—„â”€â”€ REDUNDANCJA!
                    â”‚              â”‚ rag/web/spending/etc. â”‚
                    â”‚              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚                          â”‚
                    â–¼                          â–¼
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚   Execute    â”‚          â”‚   Orchestrator   â”‚
            â”‚   Directly   â”‚          â”‚   + Search       â”‚
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚                          â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                               â–¼
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚  LLM Call #3     â”‚
                    â”‚  (response gen)  â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                               â”‚
                               â–¼
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚     RESPONSE     â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Kluczowe pliki

| Plik | OdpowiedzialnoÅ›Ä‡ |
|------|------------------|
| `app/agent/router.py` | AgentRouter - wybÃ³r narzÄ™dzia via LLM |
| `app/agent/tools.py` | Definicje 10 narzÄ™dzi + Pydantic models |
| `app/agent/validator.py` | Security (prompt injection, URL sanitization) |
| `app/chat/agent_executor.py` | Wykonywanie ACTION_TOOLS |
| `app/chat/orchestrator.py` | Pipeline dla ORCHESTRATOR_TOOLS |
| `app/chat/intent_classifier.py` | Klasyfikacja intencji (redundantna z agentem) |

### Obecne narzÄ™dzia (10)

| NarzÄ™dzie | Typ | Opis |
|-----------|-----|------|
| `create_note` | ACTION | Tworzenie notatki |
| `create_bookmark` | ACTION | Zapisywanie zakÅ‚adki |
| `summarize_url` | ACTION | Podsumowanie artykuÅ‚u |
| `list_recent` | ACTION | Lista ostatnich elementÃ³w |
| `search_knowledge` | ORCHESTRATOR | RAG - baza wiedzy |
| `search_web` | ORCHESTRATOR | Wyszukiwanie w internecie |
| `get_spending` | ORCHESTRATOR | Analityka wydatkÃ³w |
| `get_inventory` | ORCHESTRATOR | Stan spiÅ¼arni |
| `get_weather` | ORCHESTRATOR | Pogoda |
| `answer_directly` | ORCHESTRATOR | OdpowiedÅº bez narzÄ™dzi |

---

## Zidentyfikowane problemy

### Problem 1: PodwÃ³jna klasyfikacja (REDUNDANCJA)

**Opis:** Agent wybiera narzÄ™dzie (np. `get_spending`), ale orchestrator i tak odpala IntentClassifier ktÃ³ry ponownie klasyfikuje jako "spending".

**WpÅ‚yw:**
- Dodatkowy LLM call (~4s latency)
- Potencjalne niespÃ³jnoÅ›ci miÄ™dzy klasyfikacjami
- Marnowanie tokenÃ³w

**PrzykÅ‚ad:**
```
User: "Ile wydaÅ‚em w Biedronce?"
Agent: get_spending (store=Biedronka)     â† LLM #1
IntentClassifier: spending               â† LLM #2 (redundantny!)
```

---

### Problem 2: Utrata kontekstu wynikÃ³w narzÄ™dzi

**Opis:** Po wykonaniu narzÄ™dzia (np. `summarize_url`), agent nie widzi wyniku w kolejnych wiadomoÅ›ciach.

**WpÅ‚yw:**
- "Zapisz to jako notatkÄ™" po podsumowaniu â†’ agent nie wie co zapisaÄ‡
- Wymaga od uÅ¼ytkownika powtarzania informacji

**PrzykÅ‚ad:**
```
User: "Podsumuj https://example.com/article"
Agent: summarize_url â†’ "ArtykuÅ‚ o AI..."

User: "Zapisz to jako notatkÄ™"
Agent: create_note â†’ content=??? (nie widzi podsumowania)
```

---

### Problem 3: Brak mechanizmu dopytywania

**Opis:** Gdy intencja jest niejasna, agent zgaduje zamiast pytaÄ‡.

**WpÅ‚yw:**
- BÅ‚Ä™dne wykonanie akcji
- Frustracja uÅ¼ytkownika

**PrzykÅ‚ad:**
```
User: "Zapisz to"
Agent: create_note(title="To", content="to")  â† zgadywanie
Lepiej: "Co dokÅ‚adnie chcesz zapisaÄ‡?"
```

---

### Problem 4: Brak confidence scoring

**Opis:** Agent nie sygnalizuje pewnoÅ›ci swojego wyboru.

**WpÅ‚yw:**
- Nie moÅ¼na automatycznie triggerowaÄ‡ dopytywania
- Brak moÅ¼liwoÅ›ci fallbacku przy niskiej pewnoÅ›ci

---

### Problem 5: Brak obsÅ‚ugi wielu intencji

**Opis:** "Podsumuj link i zapisz jako zakÅ‚adkÄ™" â†’ tylko jedna akcja.

**WpÅ‚yw:**
- UÅ¼ytkownik musi dzieliÄ‡ polecenia
- Nienaturalna interakcja

---

### Problem 6: Brak personalizacji

**Opis:** Agent nie zna preferencji uÅ¼ytkownika.

**WpÅ‚yw:**
- Musi pytaÄ‡ o oczywiste rzeczy (miasto dla pogody)
- Brak kontekstu (ulubione sklepy, strefa czasowa)

---

## Plan implementacji

### Faza 1: Tool Result Memory

**Cel:** Agent widzi wyniki poprzednich narzÄ™dzi i moÅ¼e ich uÅ¼yÄ‡.

**Status:** âœ… Zaimplementowane

**Priorytet:** ğŸ”´ Wysoki

**Szacowany czas:** 2-3h

#### Zadania

- [x] **1.1** RozszerzyÄ‡ `AgentExecutionResult` o pole `history_entry`
- [x] **1.2** Modyfikacja `ChatAgentProcessor.process()` - generowanie history_entry z `[TOOL_RESULT]`
- [x] **1.3** Format wiadomoÅ›ci z wynikiem narzÄ™dzia w historii: `[TOOL_RESULT: tool_name]\n<treÅ›Ä‡>`
- [x] **1.4** Update system prompt - instrukcja uÅ¼ywania `[TOOL_RESULT]`
- [x] **1.5** Testy manualne scenariusza "podsumuj â†’ zapisz"

#### SzczegÃ³Å‚y techniczne

**1.1 Rozszerzenie AgentCallLog**

Plik: `app/agent/router.py`

```python
@dataclass
class AgentCallLog:
    # ... existing fields ...
    result_text: Optional[str] = None  # NEW: wynik wykonania narzÄ™dzia
```

**1.2 Modyfikacja ChatAgentProcessor**

Plik: `app/chat/agent_executor.py`

```python
async def process(
    self,
    message: str,
    db_session: AsyncSession,
    conversation_history: Optional[list[dict]] = None,
) -> AgentExecutionResult:
    # ... existing code ...

    # Po udanym wykonaniu ACTION_TOOL, dodaj wynik do historii
    if result.executed and result.result_text:
        # ZwrÃ³Ä‡ info Å¼e naleÅ¼y dodaÄ‡ do historii
        result.history_entry = {
            "role": "assistant",
            "content": f"[TOOL_RESULT: {result.tool}]\n{result.result_text}",
            "is_tool_result": True,
        }

    return result
```

**1.3 Format wiadomoÅ›ci**

```
[TOOL_RESULT: summarize_url]
**Podsumowanie:**
ArtykuÅ‚ omawia najnowsze trendy w AI...

**Tagi:** AI, machine learning
**Kategoria:** Technologia
```

**1.4 Update system prompt**

Plik: `app/agent/router.py`

```python
SYSTEM_PROMPT_TEMPLATE = """\
...existing prompt...

WYKORZYSTANIE WYNIKÃ“W POPRZEDNICH NARZÄ˜DZI:
- JeÅ›li w historii widzisz [TOOL_RESULT: nazwa_narzÄ™dzia], to jest wynik poprzedniej operacji
- MoÅ¼esz uÅ¼yÄ‡ tej treÅ›ci jako argumentu dla kolejnego narzÄ™dzia
- PrzykÅ‚ad: jeÅ›li user mÃ³wi "zapisz to" po [TOOL_RESULT: summarize_url],
  uÅ¼yj treÅ›ci podsumowania jako content w create_note
"""
```

#### Kryteria akceptacji

- [x] Po `summarize_url`, "zapisz to jako notatkÄ™" tworzy notatkÄ™ z podsumowaniem
- [x] Agent poprawnie parsuje `[TOOL_RESULT]` z historii
- [x] Wyniki sÄ… przechowywane w bazie (do debugowania)

**Wynik testu (2026-02-05):** âœ… PASS - Agent poprawnie wyciÄ…ga treÅ›Ä‡ z `[TOOL_RESULT: summarize_url]` i tworzy notatkÄ™ z podsumowaniem.

---

### Faza 2: Zunifikowana klasyfikacja

**Cel:** Eliminacja redundantnego IntentClassifier - agent zwraca info dla orchestratora.

**Status:** âœ… Zaimplementowane

**Priorytet:** ğŸ”´ Wysoki

**Szacowany czas:** 3-4h

#### Zadania

- [x] **2.1** RozszerzyÄ‡ `AgentExecutionResult` o `search_strategy` i `search_query`
- [x] **2.2** Mapowanie tool â†’ search_strategy (`TOOL_TO_STRATEGY` w agent_executor.py)
- [x] **2.3** Modyfikacja orchestratora - uÅ¼ycie strategii z agenta (parametry `agent_search_strategy`, `agent_search_query`)
- [x] **2.4** Zachowanie IntentClassifier jako fallback (gdy agent nie wywoÅ‚any)
- [x] **2.5** Testy porÃ³wnawcze (przed/po)
- [ ] **2.6** Pomiar redukcji latency (do zrobienia w produkcji)

#### SzczegÃ³Å‚y techniczne

**2.1 Rozszerzony format odpowiedzi**

Plik: `app/agent/router.py`

```python
# Nowy system prompt fragment
"""
Odpowiedz JSON w formacie:
{
    "tool": "nazwa_narzÄ™dzia",
    "arguments": {"param1": "wartoÅ›Ä‡1"},
    "search_strategy": "rag|web|both|spending|inventory|weather|direct",
    "search_query": "przeformuÅ‚owane zapytanie do wyszukiwania"
}

search_strategy:
- "rag" - przeszukaj osobistÄ… bazÄ™ wiedzy
- "web" - przeszukaj internet
- "both" - przeszukaj bazÄ™ i internet
- "spending" - zapytanie o wydatki/paragony
- "inventory" - zapytanie o spiÅ¼arniÄ™
- "weather" - zapytanie o pogodÄ™
- "direct" - odpowiedz bez wyszukiwania
"""
```

**2.2 Mapowanie tool â†’ strategy**

```python
TOOL_TO_STRATEGY = {
    "create_note": "direct",
    "create_bookmark": "direct",
    "summarize_url": "direct",
    "list_recent": "direct",
    "search_knowledge": "rag",
    "search_web": "web",
    "get_spending": "spending",
    "get_inventory": "inventory",
    "get_weather": "weather",
    "answer_directly": "direct",
}
```

**2.3 Modyfikacja orchestratora**

Plik: `app/chat/orchestrator.py`

```python
async def process_message(
    message: str,
    session_id: UUID,
    db_session: AsyncSession,
    agent_result: Optional[AgentExecutionResult] = None,  # NEW
    max_history: Optional[int] = None,
) -> ChatResponse:
    # ...

    # UÅ¼yj strategii z agenta jeÅ›li dostÄ™pna
    if agent_result and agent_result.search_strategy:
        intent = agent_result.search_strategy
        search_query = agent_result.search_query or message
        # PomiÅ„ IntentClassifier!
    else:
        # Fallback do IntentClassifier
        classified = await intent_classifier.classify_intent(message, history)
        intent = classified.intent
        search_query = classified.query or message
```

#### Kryteria akceptacji

- [x] Orchestrator uÅ¼ywa strategii z agenta (brak podwÃ³jnego LLM call)
- [ ] Latency zmniejszona o ~4s dla ORCHESTRATOR_TOOLS (do pomiaru w produkcji)
- [x] Fallback do IntentClassifier gdy agent nie zwraca strategii

**Wynik testu (2026-02-05):** âœ… PASS - Agent zwraca `get_spending` z `search_strategy: spending` dla "co jadÅ‚em w tym tygodniu". Orchestrator pomija IntentClassifier gdy strategy dostÄ™pna.

---

### Faza 3: NarzÄ™dzie ask_clarification

**Cel:** Agent moÅ¼e dopytywaÄ‡ zamiast zgadywaÄ‡.

**Status:** âœ… Zaimplementowane

**Priorytet:** ğŸŸ¡ Åšredni

**Szacowany czas:** 2-3h

#### Zadania

- [x] **3.1** DodaÄ‡ model `AskClarificationArgs` w tools.py
- [x] **3.2** DodaÄ‡ definicjÄ™ narzÄ™dzia do TOOL_DEFINITIONS
- [x] **3.3** ZarejestrowaÄ‡ w ToolName enum
- [x] **3.4** Executor w agent_executor.py (`execute_ask_clarification`)
- [x] **3.5** ObsÅ‚uga w ACTION_TOOLS i TOOL_TO_STRATEGY
- [x] **3.6** Update system prompt - kiedy uÅ¼ywaÄ‡ (sekcja "KIEDY UÅ»YWAÄ† ask_clarification")

#### SzczegÃ³Å‚y techniczne

**3.1 Model argumentÃ³w**

Plik: `app/agent/tools.py`

```python
class AskClarificationArgs(BaseModel):
    """Arguments for ask_clarification tool."""

    question: str = Field(
        ...,
        min_length=5,
        max_length=500,
        description="Pytanie do uÅ¼ytkownika"
    )
    options: Optional[list[str]] = Field(
        default=None,
        max_length=5,
        description="Sugerowane odpowiedzi (max 5)"
    )
    context: Optional[str] = Field(
        default=None,
        max_length=200,
        description="Kontekst dlaczego pytasz"
    )

    @field_validator("options", mode="before")
    @classmethod
    def limit_options(cls, v: Any) -> Optional[list[str]]:
        if v is None:
            return None
        if isinstance(v, list):
            return [str(o).strip()[:50] for o in v[:5] if str(o).strip()]
        return None
```

**3.2 Definicja narzÄ™dzia**

```python
{
    "name": "ask_clarification",
    "description": (
        "Dopytaj uÅ¼ytkownika gdy brakuje kluczowych informacji lub intencja jest niejasna. "
        "UÅ¼yj gdy: "
        "1) UÅ¼ytkownik mÃ³wi 'to', 'tamto', 'tego' bez kontekstu w historii; "
        "2) Brak wymaganego parametru (np. 'zapisz' bez treÅ›ci); "
        "3) Wieloznaczne polecenie (np. 'pokaÅ¼ ostatnie' - czego?); "
        "4) NiepeÅ‚na informacja (np. 'wydatki' - jaki okres? jaki sklep?)."
    ),
    "parameters": {
        "question": "Pytanie do uÅ¼ytkownika [wymagane]",
        "options": "Lista sugerowanych odpowiedzi, max 5 (opcjonalne)",
        "context": "KrÃ³tki kontekst dlaczego pytasz (opcjonalne)",
    },
    "required": ["question"],
}
```

**3.5 ObsÅ‚uga w Telegram**

```python
# JeÅ›li tool == "ask_clarification":
if result.tool == "ask_clarification" and result.arguments:
    question = result.arguments.get("question", "")
    options = result.arguments.get("options", [])

    if options:
        # WyÅ›lij z inline keyboard
        keyboard = [[InlineKeyboardButton(opt, callback_data=f"clarify:{opt}")]
                    for opt in options]
        await update.message.reply_text(question, reply_markup=InlineKeyboardMarkup(keyboard))
    else:
        await update.message.reply_text(question)
```

#### Kryteria akceptacji

- [~] "Zapisz to" bez kontekstu â†’ agent pyta "Co chcesz zapisaÄ‡?"
- [ ] "PokaÅ¼ ostatnie" â†’ agent pyta "Jakiego typu? notatki, paragony, zakÅ‚adki?"
- [x] Telegram wyÅ›wietla opcje jako przyciski gdy podane

**Wynik testu (2026-02-05):** âš ï¸ PARTIAL - Implementacja kodu jest poprawna, ale model (qwen2.5:7b) nie zawsze
uÅ¼ywa `ask_clarification` dla niejasnych intencji.

**UPDATE (2026-02-05 - po dostrojeniu promptu + heurystyki):** âœ… PASS
- Rozbudowano sekcjÄ™ few-shot examples pokazujÄ…cÄ… kiedy uÅ¼ywaÄ‡ ask_clarification
- Dodano heurystyki w `router.py` dla typowych przypadkÃ³w:
  - "zapisz to" (bez kontekstu) â†’ ask_clarification âœ…
  - "szukaj" (bez tematu) â†’ ask_clarification âœ…
  - "pokaÅ¼ ostatnie" (bez typu) â†’ ask_clarification âœ…
- Heurystyki wykrywajÄ…: trivial search queries, list_recent bez explicit type

---

### Faza 4: Confidence scoring

**Cel:** Agent sygnalizuje pewnoÅ›Ä‡ wyboru, automatyczny fallback do ask_clarification.

**Status:** âœ… Zaimplementowane

**Priorytet:** ğŸŸ¡ Åšredni

**Szacowany czas:** 2h

#### Zadania

- [x] **4.1** RozszerzyÄ‡ format odpowiedzi o pole `confidence` (0.0-1.0)
- [x] **4.2** Update system prompt z instrukcjÄ… oceny pewnoÅ›ci
- [x] **4.3** Threshold w konfiguracji (`AGENT_CONFIDENCE_THRESHOLD=0.6`)
- [x] **4.4** Auto-fallback do ask_clarification gdy confidence < threshold
- [x] **4.5** Logowanie confidence do AgentCallLog

#### SzczegÃ³Å‚y techniczne

**4.1 Rozszerzony format**

```python
# System prompt
"""
Odpowiedz JSON:
{
    "tool": "nazwa",
    "arguments": {...},
    "confidence": 0.85
}

confidence (0.0-1.0):
- 0.9-1.0: Bardzo pewny - jasne polecenie, wszystkie parametry podane
- 0.7-0.9: Pewny - intencja jasna, niektÃ³re parametry domyÅ›lne
- 0.5-0.7: Niepewny - intencja prawdopodobna ale niejasna
- 0.0-0.5: Bardzo niepewny - uÅ¼yj ask_clarification

JeÅ›li confidence < 0.6, uÅ¼yj ask_clarification zamiast zgadywaÄ‡.
"""
```

**4.3 Konfiguracja**

Plik: `app/config.py`

```python
class Settings(BaseSettings):
    # ... existing ...
    AGENT_CONFIDENCE_THRESHOLD: float = 0.6
```

**4.4 Auto-fallback**

Plik: `app/agent/router.py`

```python
def _parse_llm_response(self, response: str) -> Optional[dict]:
    # ... existing parsing ...

    # Check confidence and auto-fallback
    confidence = data.get("confidence", 1.0)
    if confidence < settings.AGENT_CONFIDENCE_THRESHOLD:
        logger.info(f"Low confidence ({confidence}), suggesting clarification")
        # MoÅ¼na tu automatycznie zamieniÄ‡ na ask_clarification
        # lub zwrÃ³ciÄ‡ info dla wyÅ¼szej warstwy

    return data
```

#### Kryteria akceptacji

- [~] Agent zwraca confidence w kaÅ¼dej odpowiedzi
- [x] Confidence < 0.6 triggeruje ask_clarification
- [x] Confidence logowane do bazy

**Wynik testu (2026-02-05):** âš ï¸ PARTIAL - Model (qwen2.5:7b) nie zawsze zwraca pole `confidence` w JSON.

**UPDATE (2026-02-05 - po dostrojeniu promptu):** âœ… PASS
- Rozbudowano sekcjÄ™ few-shot examples w prompcie
- Model teraz zwraca confidence w 100% przypadkÃ³w
- PrzykÅ‚ady po zmianach:
  - "hello" â†’ answer_directly, confidence=0.95 âœ…
  - "Zanotuj: spotkanie o 10" â†’ create_note, confidence=0.95 âœ…
  - "ile wydaÅ‚em?" â†’ get_spending, confidence=0.85 âœ…
  - "znajdÅº coÅ› o AI" â†’ search_knowledge, confidence=0.85 âœ…

---

### Faza 5: Multi-tool support

**Cel:** ObsÅ‚uga wielu narzÄ™dzi w jednym zapytaniu.

**Status:** âœ… Zaimplementowane

**Priorytet:** ğŸŸ¢ Niski

**Szacowany czas:** 4-5h

#### Zadania

- [x] **5.1** RozszerzyÄ‡ format o `tools` array (alternatywa dla `tool`)
- [x] **5.2** Sekwencyjne wykonywanie narzÄ™dzi
- [x] **5.3** Przekazywanie wynikÃ³w miÄ™dzy narzÄ™dziami
- [x] **5.4** ObsÅ‚uga bÅ‚Ä™dÃ³w w Å‚aÅ„cuchu (partial results)
- [x] **5.5** Limit liczby narzÄ™dzi (max 3)
- [x] **5.6** Update system prompt z przykÅ‚adami multi-tool

#### SzczegÃ³Å‚y techniczne

**5.1 Rozszerzony format**

```python
# Opcja A: Array narzÄ™dzi
{
    "tools": [
        {"tool": "summarize_url", "arguments": {"url": "..."}},
        {"tool": "create_bookmark", "arguments": {"url": "..."}}
    ]
}

# Opcja B: Pojedyncze narzÄ™dzie (backwards compatible)
{
    "tool": "create_note",
    "arguments": {...}
}
```

**5.2 Sekwencyjne wykonywanie**

```python
async def execute_tool_chain(
    tools: list[dict],
    db_session: AsyncSession,
) -> list[AgentExecutionResult]:
    results = []
    context = {}  # Wyniki poprzednich narzÄ™dzi

    for tool_spec in tools[:3]:  # Max 3 narzÄ™dzia
        tool_name = tool_spec["tool"]
        arguments = tool_spec["arguments"]

        # Wstrzyknij wyniki poprzednich narzÄ™dzi
        if context and "{previous_result}" in str(arguments):
            arguments = inject_previous_result(arguments, context)

        result = await execute_single_tool(tool_name, arguments, db_session)
        results.append(result)

        if not result.executed:
            break  # Przerwij Å‚aÅ„cuch przy bÅ‚Ä™dzie

        context[tool_name] = result.result_text

    return results
```

#### Kryteria akceptacji

- [x] "Podsumuj link i zapisz jako zakÅ‚adkÄ™" â†’ 2 akcje wykonane
- [x] Wynik pierwszego narzÄ™dzia dostÄ™pny dla drugiego (ToolChainContext)
- [x] BÅ‚Ä…d w pierwszym narzÄ™dziu przerywa Å‚aÅ„cuch (partial_success)
- [x] Max 3 narzÄ™dzia w jednym zapytaniu (MAX_TOOLS_IN_CHAIN=3)

**Wynik implementacji (2026-02-05):** âœ… PASS
- Format B: `{"tools": [{...}, {...}], "confidence": 0.9}`
- `validate_multi_tool_call()` obsÅ‚uguje oba formaty (A i B)
- `execute_tool_chain()` wykonuje narzÄ™dzia sekwencyjnie z przekazywaniem kontekstu
- `_inject_chain_context()` automatycznie mapuje wyniki (np. summarize_url â†’ create_note.content)
- `AgentResponse.is_multi`, `.tools`, `.arguments_list` dla obsÅ‚ugi w executor
- System prompt rozszerzony o przykÅ‚ady multi-tool

---

### Faza 6: Profil uÅ¼ytkownika

**Cel:** Personalizacja agenta na podstawie preferencji.

**Status:** âœ… Zaimplementowane

**Priorytet:** ğŸŸ¢ Niski

**Szacowany czas:** 2-3h

#### Zadania

- [x] **6.1** Model `UserProfile` w bazie danych
- [x] **6.2** API endpoint do zarzÄ…dzania profilem
- [x] **6.3** Wstrzykiwanie profilu do system prompt
- [x] **6.4** DomyÅ›lne wartoÅ›ci (miasto, timezone)
- [x] **6.5** Telegram command `/profile`

#### SzczegÃ³Å‚y techniczne

**6.1 Model bazy danych**

Plik: `app/db/models.py`

```python
class UserProfile(Base):
    __tablename__ = "user_profiles"

    id = Column(UUID, primary_key=True, default=uuid4)
    telegram_user_id = Column(BigInteger, unique=True, nullable=True)

    # Preferencje
    default_city = Column(String(100), default="KrakÃ³w")
    timezone = Column(String(50), default="Europe/Warsaw")
    preferred_language = Column(String(10), default="pl")
    favorite_stores = Column(ARRAY(String), default=[])

    # Statystyki (do personalizacji)
    most_used_tools = Column(JSONB, default={})

    created_at = Column(DateTime, default=datetime.utcnow)
    updated_at = Column(DateTime, default=datetime.utcnow, onupdate=datetime.utcnow)
```

**6.3 Wstrzykiwanie do prompt**

```python
def get_system_prompt(user_profile: Optional[UserProfile] = None) -> str:
    base_prompt = SYSTEM_PROMPT_TEMPLATE.format(...)

    if user_profile:
        profile_section = f"""
PROFIL UÅ»YTKOWNIKA:
- DomyÅ›lne miasto: {user_profile.default_city}
- Strefa czasowa: {user_profile.timezone}
- Ulubione sklepy: {', '.join(user_profile.favorite_stores) or 'nie okreÅ›lono'}

UÅ¼ywaj tych informacji jako domyÅ›lnych wartoÅ›ci gdy uÅ¼ytkownik ich nie poda.
"""
        base_prompt += profile_section

    return base_prompt
```

#### Kryteria akceptacji

- [x] "Jaka pogoda?" bez miasta â†’ uÅ¼ywa domyÅ›lnego z profilu
- [x] `/profile` w Telegram pokazuje i pozwala edytowaÄ‡ ustawienia
- [x] Profil persystowany w bazie

**Wynik implementacji (2026-02-05):** âœ… PASS
- Model `UserProfile` w `app/db/models.py` z polami: default_city, timezone, preferred_language, favorite_stores, most_used_tools
- Repository `UserProfileRepository` z metodami: get_by_telegram_id, get_or_create_by_telegram_id, update_preferences, increment_tool_usage
- API endpoints `/profile/*` - GET, POST, PATCH
- Alembic migration 009_add_user_profiles
- System prompt rozszerzony o sekcjÄ™ PROFIL UÅ»YTKOWNIKA gdy profil dostÄ™pny
- Telegram commands: `/profile`, `/setcity`, `/setstores`
- Callback handler dla profile: z inline keyboard do edycji miasta

---

## Harmonogram

```
TydzieÅ„ 1:
â”œâ”€â”€ Faza 1: Tool Result Memory (2-3h)
â””â”€â”€ Faza 2: Zunifikowana klasyfikacja (3-4h)

TydzieÅ„ 2:
â”œâ”€â”€ Faza 3: ask_clarification (2-3h)
â””â”€â”€ Faza 4: Confidence scoring (2h)

TydzieÅ„ 3+ (opcjonalnie):
â”œâ”€â”€ Faza 5: Multi-tool support (4-5h)
â””â”€â”€ Faza 6: Profil uÅ¼ytkownika (2-3h)
```

**CaÅ‚kowity szacowany czas:** 15-20h

---

## Metryki sukcesu

| Metryka | Obecna wartoÅ›Ä‡ | Cel | SposÃ³b pomiaru |
|---------|----------------|-----|----------------|
| Latency (ORCHESTRATOR_TOOLS) | ~8s | ~4s | Timestamp w logach |
| LLM calls per request | 3 â†’ 2 | 2 | âœ… Zredukowane gdy agent uÅ¼ywany |
| "Zapisz to" z kontekstem | 100% | >90% | âœ… TEST 3 - dziaÅ‚a z [TOOL_RESULT] |
| "Zapisz to" bez kontekstu | ~~50%~~ **100%** | >90% | âœ… Po dostrojeniu promptu + heurystyki |
| Confidence zwracany | ~~60%~~ **100%** | 100% | âœ… Po rozbudowie few-shot examples |

*Aktualizacja 2026-02-05: Po dostrojeniu promptu i dodaniu heurystyk wszystkie metryki osiÄ…gniÄ™te*

---

## Log zmian

| Data | Zmiana | Faza |
|------|--------|------|
| 2026-02-05 | Utworzenie planu | - |
| 2026-02-05 | Implementacja Tool Result Memory - `[TOOL_RESULT]` w historii | Faza 1 |
| 2026-02-05 | Zunifikowana klasyfikacja - agentâ†’orchestrator bez IntentClassifier | Faza 2 |
| 2026-02-05 | NarzÄ™dzie ask_clarification - dopytywanie przy niejasnych intencjach | Faza 3 |
| 2026-02-05 | Confidence scoring - auto-fallback przy niskiej pewnoÅ›ci | Faza 4 |
| 2026-02-05 | Migracja alembic 008 (kolumna confidence) | Faza 4 |
| 2026-02-05 | Testy manualne faz 1-4 - Tool Result Memory dziaÅ‚a, confidence czÄ™Å›ciowo | Testy |
| 2026-02-05 | Dostrojenie promptu - rozbudowa few-shot examples | Faza 3+4 |
| 2026-02-05 | Heurystyki auto-fallback - trivial search, list bez typu | Faza 3+4 |
| 2026-02-05 | Fix ToolCall validator dla ToolName enum | Bugfix |
| 2026-02-05 | Wszystkie testy OK - confidence 100%, ask_clarification dziaÅ‚a | Testy |
| 2026-02-05 | Multi-tool support - format B, execute_tool_chain(), context injection | Faza 5 |
| 2026-02-05 | User Profile - UserProfile model, API, Telegram /profile, system prompt injection | Faza 6 |

---

## Notatki implementacyjne

### ZaleÅ¼noÅ›ci miÄ™dzy fazami

```
Faza 1 (Tool Result Memory) âœ…
    â”‚
    â””â”€â”€â–º Faza 3 (ask_clarification) âœ… - moÅ¼e korzystaÄ‡ z kontekstu

Faza 2 (Zunifikowana klasyfikacja) âœ…
    â”‚
    â””â”€â”€â–º Faza 4 (Confidence) âœ… - rozszerza ten sam format

Faza 4 (Confidence) âœ…
    â”‚
    â””â”€â”€â–º Faza 3 (ask_clarification) âœ… - auto-trigger przy low confidence

Faza 5 (Multi-tool) âœ… - niezaleÅ¼na, zaimplementowana
Faza 6 (Profil) âœ… - niezaleÅ¼na, zaimplementowana
```

### Ryzyka

| Ryzyko | PrawdopodobieÅ„stwo | Mitygacja |
|--------|-------------------|-----------|
| ZwiÄ™kszenie dÅ‚ugoÅ›ci promptu | Wysokie | Monitoruj token count, optymalizuj |
| Regresja w istniejÄ…cych scenariuszach | Åšrednie | Zachowaj testy z raportu (25 cases) |
| ZwiÄ™kszona zÅ‚oÅ¼onoÅ›Ä‡ kodu | Åšrednie | Dobre komentarze, modularnoÅ›Ä‡ |

---

## Appendix: PrzykÅ‚adowe scenariusze testowe

### Scenariusz: Tool Result Memory

```
1. User: "Podsumuj https://example.com/ai-article"
   Agent: summarize_url â†’ "ArtykuÅ‚ o trendach AI w 2026..."

2. User: "Zapisz to jako notatkÄ™"
   Agent: create_note(title="Trendy AI 2026", content="ArtykuÅ‚ o trendach AI...")
   âœ… Oczekiwany wynik: notatka z treÅ›ciÄ… podsumowania
```

### Scenariusz: ask_clarification

```
1. User: "Zapisz"
   Agent: ask_clarification(
       question="Co chcesz zapisaÄ‡?",
       options=["Ostatnie podsumowanie", "NowÄ… notatkÄ™", "Link"]
   )

2. User: "NowÄ… notatkÄ™ o spotkaniu"
   Agent: create_note(title="Spotkanie", content="o spotkaniu")
```

### Scenariusz: Multi-tool

```
1. User: "Podsumuj ten artykuÅ‚ i dodaj do zakÅ‚adek: https://..."
   Agent: tools=[
       {tool: "summarize_url", args: {url: "..."}},
       {tool: "create_bookmark", args: {url: "..."}}
   ]
   Wynik: Podsumowanie + zakÅ‚adka utworzona
```
