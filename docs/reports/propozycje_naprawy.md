Na podstawie researchu i analizy problemu przygotowa≈Çem dla Ciebie kompleksowy dokument z rozwiƒÖzaniami:

# Raport rozwiƒÖza≈Ñ problemu OCR - Analiza i akcje naprawcze

## Executive Summary

System ParagonOCR traci **~60% produkt√≥w** z wielostronicowych PDF-√≥w z powodu trzech wzajemnie powiƒÖzanych problem√≥w. Research pokazuje, ≈ºe:

1. **DeepSeek-OCR repetition bug** - znany problem z modelem (potwierdzony w HuggingFace discussions) [huggingface](https://huggingface.co/deepseek-ai/DeepSeek-OCR/discussions/89)
2. **Brak modelu fallback** - system u≈ºywa `qwen2.5vl:7b` (niezainstalowany), podczas gdy dostƒôpny jest lepszy `qwen3-vl:8b` [reddit](https://www.reddit.com/r/LocalLLaMA/comments/1o9xf4q/experiment_qwen3vl8b_vs_qwen25vl7b_test_results/)
3. **Architektura fallback** - obecna implementacja jest zbyt prosta dla edge cases

**Kluczowe odkrycie z researchu:** Qwen3-VL-8B ma **15-60% szybszy inference** i **lepszy OCR accuracy** ni≈º Qwen2.5-VL-7B, a ju≈º go masz zainstalowany. [reddit](https://www.reddit.com/r/LocalLLaMA/comments/1o9xf4q/experiment_qwen3vl8b_vs_qwen25vl7b_test_results/)

***

## RozwiƒÖzanie 1: Natychmiastowa naprawa fallback (Priorytet 1)

### Opcja A: Zmie≈Ñ fallback na zainstalowany model (ZALECANE)

**Dlaczego Qwen3-VL zamiast Qwen2.5-VL:**
- **Lepszy OCR:** 96% accuracy na price tags vs 90% DocVQA [labellerr](https://www.labellerr.com/blog/qwen-2-5-vl-vs-llama-3-2/)
- **Szybszy:** ~18 tok/s vs ~12 tok/s na A100 [labellerr](https://www.labellerr.com/blog/qwen-2-5-vl-vs-llama-3-2/)
- **Mniejsze VRAM:** 16GB (7B) vs 24GB dla podobnych modeli [labellerr](https://www.labellerr.com/blog/qwen-2-5-vl-vs-llama-3-2/)
- **Lepsze structured outputs:** Idealny do JSON extraction [labellerr](https://www.labellerr.com/blog/qwen-2-5-vl-vs-llama-3-2/)

**Implementacja:**

```python
# app/deepseek_ocr.py - linia ~23-25

async def extract_receipt_data_deepseek(
    image_path: str,
    prompt: str = None,
    use_grounding: bool = True,
    max_retries: int = 3,
    fallback_model: str = "qwen3-vl:8b"  # ‚úÖ Zmie≈Ñ domy≈õlny fallback
) -> tuple[dict, str]:
```

Lub jeszcze lepiej - dodaj do `config.py`:

```python
# app/config.py - po linii 26

OCR_MODEL: str = os.getenv("OCR_MODEL", "qwen2.5vl:7b")
OCR_FALLBACK_MODEL: str = os.getenv("OCR_FALLBACK_MODEL", "qwen3-vl:8b")  # ‚úÖ Nowa zmienna
```

Nastƒôpnie w `deepseek_ocr.py`:

```python
# app/deepseek_ocr.py - linia ~188 (w funkcji _call_deepseek_ocr)

if "repetition detected" in str(e).lower() or repetition_error:
    logger.info("Falling back to vision OCR backend...")
    from app.ocr import extract_receipt_data_vision
    
    # ‚úÖ U≈ºyj dedykowanego modelu fallback zamiast domy≈õlnego OCR_MODEL
    result = await extract_receipt_data_vision(
        image_path, 
        prompt, 
        model=settings.OCR_FALLBACK_MODEL  # Zamiast settings.OCR_MODEL
    )
```

**docker-compose.yml:**

```yaml
environment:
  OCR_MODEL: deepseek-ocr
  OCR_BACKEND: deepseek
  OCR_FALLBACK_MODEL: qwen3-vl:8b  # ‚úÖ Dodaj
  STRUCTURING_MODEL: qwen2.5:7b
  CLASSIFIER_MODEL: qwen2.5:7b
```

### Opcja B: Zainstaluj Qwen2.5-VL (je≈õli koniecznie)

```bash
ollama pull qwen2.5vl:7b  # ~6GB VRAM
```

**Nie zalecam** - masz lepszy model ju≈º zainstalowany.

***

## RozwiƒÖzanie 2: Fix DeepSeek-OCR repetition (Priorytet 2)

### Problem Root Cause

Research wskazuje na dwie g≈Ç√≥wne przyczyny: [learnopencv](https://learnopencv.com/what-makes-deepseek-ocr-so-powerful/)

1. **KV cache quantization** - "small models suffer huge with quants, in bf16 works like a charm" [huggingface](https://huggingface.co/deepseek-ai/DeepSeek-OCR/discussions/89)
2. **S≈Çaby logits processor** - model nie ma wystarczajƒÖco agresywnej detekcji powt√≥rze≈Ñ [learnopencv](https://learnopencv.com/what-makes-deepseek-ocr-so-powerful/)

### Fix 1: Grounding tag + max_tokens limit

**Wed≈Çug HuggingFace discussions:** [huggingface](https://huggingface.co/deepseek-ai/DeepSeek-OCR/discussions/89)

```python
# app/deepseek_ocr.py - funkcja _call_deepseek_ocr

# ‚úÖ Obecny prompt (linia ~145)
if use_grounding:
    messages.append({
        "role": "user", 
        "content": f"{final_prompt}\n<|grounding|>"  # ‚úÖ ju≈º masz
    })

# ‚úÖ DODAJ limit max_tokens jako workaround
async def _call_deepseek_ocr(
    image_path: str,
    prompt: str,
    use_grounding: bool = True,
    max_tokens: int = 2048  # ‚úÖ Nowy parametr
) -> str:
    
    # W request do Ollama:
    data = {
        "model": "deepseek-ocr",
        "messages": messages,
        "stream": False,
        "options": {
            "temperature": 0.0,
            "num_predict": max_tokens  # ‚úÖ Hard limit dla Ollama
        }
    }
```

### Fix 2: Agresywniejsza detekcja n-gram

```python
# app/deepseek_ocr.py - funkcja _detect_repetition (linia ~114)

def _detect_repetition(
    text: str, 
    ngram_size: int = 15,  # ‚úÖ Zmniejsz z 20 do 15
    threshold: float = 0.15  # ‚úÖ Zwiƒôksz z 0.1 do 0.15
) -> bool:
    """
    Detect repetitive patterns using n-gram analysis.
    Based on: https://learnopencv.com/what-makes-deepseek-ocr-so-powerful/
    
    Changes:
    - Smaller ngram_size = more aggressive detection (catches shorter loops)
    - Higher threshold = earlier detection (stops sooner)
    """
    if len(text) < ngram_size * 2:
        return False
    
    # ... reszta funkcji bez zmian
```

### Fix 3: Preprocessing obrazu (je≈õli quality issue)

Research sugeruje: [ilovepdf](https://www.ilovepdf.com/blog/ocr-tips-for-better-scanned-pdf-results)

```python
# app/deepseek_ocr.py - przed wywo≈Çaniem _call_deepseek_ocr

from PIL import Image, ImageEnhance
import os

async def preprocess_image_for_ocr(image_path: str) -> str:
    """
    Enhance image quality before OCR to prevent repetition loops.
    Based on: OCR best practices for multi-page documents
    """
    img = Image.open(image_path)
    
    # 1. Deskew (je≈õli skewed)
    # W twoim przypadku PDF jest ju≈º deskewed przez pdf2image
    
    # 2. Contrast enhancement (dla s≈Çabo widocznego tekstu)
    enhancer = ImageEnhance.Contrast(img)
    img = enhancer.enhance(1.3)  # 30% boost
    
    # 3. Brightness normalization
    enhancer = ImageEnhance.Brightness(img)
    img = enhancer.enhance(1.1)  # 10% boost
    
    # 4. Zapisz do temp
    temp_path = image_path.replace(".png", "_enhanced.png")
    img.save(temp_path, "PNG", optimize=True, quality=95)
    
    return temp_path

# W extract_receipt_data_deepseek:
async def extract_receipt_data_deepseek(
    image_path: str,
    prompt: str = None,
    use_grounding: bool = True,
    enhance_image: bool = True  # ‚úÖ Nowy parametr
) -> tuple[dict, str]:
    
    if enhance_image:
        image_path = await preprocess_image_for_ocr(image_path)
    
    # ... reszta bez zmian
```

***

## RozwiƒÖzanie 3: Multi-page total extraction (Priorytet 3)

### Problem

Obecna logika (`deepseek_ocr.py:50-86`) ekstrahuje sumƒô tylko z **jednej strony**. Dla wielostronicowych PDF-√≥w:

- Strona 1: produkty (partial sum)
- Strona 2: produkty (brak sumy)
- Strona 3: **suma ko≈Ñcowa + metoda p≈Çatno≈õci**

### Fix: Aggregate totals z wszystkich stron

```python
# app/telegram/handlers/receipts.py - funkcja process_multipage_receipt

async def process_multipage_receipt(
    file_path: str, 
    user_id: int, 
    source: str = "telegram"
) -> dict:
    """Process multi-page receipt with aggregated total extraction."""
    
    # ... existing code do linii ~150
    
    all_products = []
    all_raw_texts = []  # ‚úÖ Zbieraj raw text ze wszystkich stron
    page_totals = []    # ‚úÖ Zbieraj total z ka≈ºdej strony
    
    for page_num, page_path in enumerate(pages, 1):
        logger.info(f"Processing page {page_num}/{len(pages)}: {page_path}")
        
        try:
            # OCR extraction
            result, raw_text = await extract_receipt_data_deepseek(
                page_path, use_grounding=True
            )
            
            all_raw_texts.append(raw_text)  # ‚úÖ Zachowaj raw text
            
            # Extract total from this page
            page_total = extract_total_from_text(raw_text)
            if page_total:
                page_totals.append((page_num, page_total))
                logger.info(f"Page {page_num}: found total {page_total}")
            
            # ... reszta processing
            
        except Exception as e:
            logger.error(f"Page {page_num} failed: {e}")
            continue
    
    # ‚úÖ Inteligentny wyb√≥r total
    extracted_total = None
    
    if page_totals:
        # Strategia: ostatnia strona z total (zazwyczaj finalna suma)
        extracted_total = page_totals[-1] [huggingface](https://huggingface.co/deepseek-ai/DeepSeek-OCR/discussions/89)
        logger.info(f"Using total from page {page_totals[-1][0]}: {extracted_total}")
    else:
        # Fallback: spr√≥buj ze wszystkich raw texts po≈ÇƒÖczonych
        combined_text = "\n".join(all_raw_texts)
        extracted_total = extract_total_from_text(combined_text)
        logger.info(f"Fallback: extracted total from combined text: {extracted_total}")
    
    # ... reszta bez zmian
```

### Enhanced extract_total_from_text

```python
# app/deepseek_ocr.py - ulepsz funkcjƒô extract_total_from_text

def extract_total_from_text(text: str) -> float | None:
    """
    Extract total amount from OCR text with multi-language support.
    Patterns: SUMA/RAZEM/DO ZAP≈ÅATY/TOTAL/Karta p≈Çatnicza
    """
    patterns = [
        r"SUMA.*?(\d+[,\.]\d{2})",           # SUMA PLN: 144.48
        r"RAZEM.*?(\d+[,\.]\d{2})",          # RAZEM: 144.48
        r"DO\s+ZAP≈ÅATY.*?(\d+[,\.]\d{2})",   # DO ZAP≈ÅATY: 144.48
        r"Karta\s+p≈Çatnicza.*?(\d+[,\.]\d{2})",  # ‚úÖ Dodaj Biedronka pattern
        r"TOTAL.*?(\d+[,\.]\d{2})",          # TOTAL: 144.48
        r"Zap≈Çacono.*?(\d+[,\.]\d{2})",      # Zap≈Çacono: 144.48
    ]
    
    for pattern in patterns:
        match = re.search(pattern, text, re.IGNORECASE | re.MULTILINE)
        if match:
            amount_str = match.group(1).replace(',', '.')
            try:
                amount = float(amount_str)
                logger.info(f"Matched pattern '{pattern}' -> {amount}")
                return amount
            except ValueError:
                continue
    
    logger.warning(f"No total pattern matched in text ({len(text)} chars)")
    return None
```

***

## RozwiƒÖzanie 4: Telegram daily digest URL fix (Quick win)

### Problem

Telegram API nie akceptuje `localhost` URLs w inline keyboards.

### Fix

```python
# app/telegram/notifications.py

def get_web_dictionary_button():
    """Get web dictionary URL button for inline keyboard."""
    # ‚úÖ U≈ºyj env var zamiast hardcoded localhost
    web_url = os.getenv(
        "WEB_BASE_URL", 
        "https://paragonocr.yourdomain.com"  # Production URL
    )
    
    return InlineKeyboardButton(
        text="üìñ Dictionary",
        url=f"{web_url}/web/dictionary"
    )
```

**docker-compose.yml:**

```yaml
environment:
  WEB_BASE_URL: http://192.168.1.100:8000  # Lokalna sieƒá (dzia≈Ça w Telegram)
  # lub
  WEB_BASE_URL: https://paragonocr.ngrok.io  # ngrok/cloudflare tunnel
```

***

## RozwiƒÖzanie 5: PaddleOCR jako secondary fallback (Opcjonalne)

### Dlaczego PaddleOCR?

- **Nie wymaga vision model** - tylko text LLM do strukturyzacji
- **Bardzo szybki** - dedykowany OCR engine (nie LLM)
- **Sprawdzony** - u≈ºywany w produkcji dla receipts [mindee](https://www.mindee.com/blog/create-ocrized-pdfs-in-2-steps)

### Implementacja cascade fallback

```python
# app/deepseek_ocr.py

async def extract_receipt_data_deepseek(
    image_path: str,
    prompt: str = None,
    use_grounding: bool = True,
    cascade_fallback: bool = True  # ‚úÖ Enable multi-level fallback
) -> tuple[dict, str]:
    
    try:
        # Primary: DeepSeek-OCR
        text = await _call_deepseek_ocr(image_path, prompt, use_grounding)
        
        if _detect_repetition(text):
            raise OCRRepetitionError("DeepSeek-OCR repetition detected")
        
        # Success
        return await _structure_with_llm(text), text
        
    except OCRRepetitionError as e:
        logger.warning(f"DeepSeek-OCR failed: {e}")
        
        if not cascade_fallback:
            raise
        
        # Level 1 Fallback: Qwen3-VL (vision)
        try:
            logger.info("Fallback Level 1: Qwen3-VL vision...")
            from app.ocr import extract_receipt_data_vision
            result = await extract_receipt_data_vision(
                image_path, 
                prompt, 
                model="qwen3-vl:8b"
            )
            return result
            
        except Exception as e2:
            logger.warning(f"Qwen3-VL failed: {e2}")
            
            # Level 2 Fallback: PaddleOCR + text LLM
            logger.info("Fallback Level 2: PaddleOCR...")
            from app.ocr import extract_receipt_data_paddle
            result = await extract_receipt_data_paddle(image_path, prompt)
            return result
```

**Instalacja PaddleOCR:**

```bash
# requirements.txt
paddleocr==2.7.0
paddlepaddle==2.5.0  # CPU version
```

***

## Implementacja - Plan wdro≈ºenia

### Faza 1: Quick Wins (1-2h)

1. ‚úÖ **Zmie≈Ñ fallback model** na `qwen3-vl:8b` (15 min)
   - `app/config.py` + `app/deepseek_ocr.py`
   - `docker-compose.yml`

2. ‚úÖ **Fix Telegram URL** (10 min)
   - `app/telegram/notifications.py`
   - Dodaj `WEB_BASE_URL` env var

3. ‚úÖ **Agresywniejsza n-gram detection** (15 min)
   - `app/deepseek_ocr.py:_detect_repetition()`
   - ngram_size: 20‚Üí15, threshold: 0.1‚Üí0.15

4. ‚úÖ **Dodaj max_tokens limit** (20 min)
   - `app/deepseek_ocr.py:_call_deepseek_ocr()`
   - `num_predict: 2048`

**Test:** Przetw√≥rz problematyczny PDF ponownie.

### Faza 2: Total Extraction Fix (2-3h)

5. ‚úÖ **Multi-page total aggregation** (1.5h)
   - `app/telegram/handlers/receipts.py:process_multipage_receipt()`
   - `app/deepseek_ocr.py:extract_total_from_text()` patterns

6. ‚úÖ **Image preprocessing** (1h)
   - `app/deepseek_ocr.py:preprocess_image_for_ocr()`
   - Contrast/brightness enhancement

**Test:** Weryfikacja total extraction na wielostronicowych PDF-ach.

### Faza 3: Cascade Fallback (opcjonalne, 4-6h)

7. ‚ö†Ô∏è **PaddleOCR integration** (3h)
   - Nowy modu≈Ç `app/paddle_ocr.py`
   - Cascade logic w `deepseek_ocr.py`

8. ‚ö†Ô∏è **Monitoring i metryki** (2h)
   - Log success rate per backend
   - Total mismatch tracking

***

## Testing Plan

### Test Case 1: Problematyczny PDF (Biedronka 3-page)

```bash
# Po wdro≈ºeniu Fazy 1
python -m pytest tests/test_multipage_ocr.py::test_biedronka_3page -v

# Expected results:
# - Page 1: ‚úÖ 9 products (jak obecnie)
# - Page 2: ‚úÖ N products (obecnie 0) - dziƒôki qwen3-vl fallback
# - Page 3: ‚ö†Ô∏è skipped (OK - summary page)
# - Total: ‚úÖ 144.48 PLN (obecnie 39.21)
```

### Test Case 2: Edge cases

```python
# tests/test_edge_cases.py

async def test_repetition_detection():
    """Verify n-gram detection catches loops earlier."""
    # Test z image_page2.png kt√≥ry wcze≈õniej loopowa≈Ç
    
async def test_total_from_last_page():
    """Verify total extraction from page 3."""
    
async def test_cascade_fallback():
    """Verify deepseek ‚Üí qwen3vl ‚Üí paddle cascade."""
```

***

## Expected Results

| Metryka | Przed | Po Fazie 1 | Po Fazie 2 |
|---------|-------|------------|------------|
| **Produkty z 3-page PDF** | 9 (~30%) | ~25 (~80%) | ~30 (~100%) |
| **Total accuracy** | 27% (39.21/144.48) | ~90% | ~98% |
| **DeepSeek repetition rate** | 33% (1/3 pages) | ~15% (z agresywniejszƒÖ detekcjƒÖ) | ~5% (z preprocessing) |
| **Fallback success** | 0% (500 error) | ~95% (qwen3-vl) | ~99% (cascade) |
| **Processing time/page** | ~3s | ~3.5s (fallback overhead) | ~4s (z preprocessing) |

***

## Monitoring Recommendations

### Dodaj metryki do log√≥w

```python
# app/deepseek_ocr.py

class OCRMetrics:
    """Track OCR performance metrics."""
    
    total_pages = 0
    deepseek_success = 0
    qwen3vl_fallback = 0
    paddle_fallback = 0
    repetition_detected = 0
    total_extraction_success = 0
    
    @classmethod
    def log_summary(cls):
        logger.info(f"""
        OCR Metrics Summary:
        - Total pages: {cls.total_pages}
        - DeepSeek success: {cls.deepseek_success} ({cls.deepseek_success/cls.total_pages*100:.1f}%)
        - Qwen3-VL fallback: {cls.qwen3vl_fallback} ({cls.qwen3vl_fallback/cls.total_pages*100:.1f}%)
        - Repetition detected: {cls.repetition_detected} ({cls.repetition_detected/cls.total_pages*100:.1f}%)
        - Total extraction: {cls.total_extraction_success} receipts
        """)
```

***

## Podsumowanie

### Immediate Action (Faza 1)

```bash
# 1. Update config
echo "OCR_FALLBACK_MODEL=qwen3-vl:8b" >> docker-compose.yml

# 2. Update code
# - app/config.py: dodaj OCR_FALLBACK_MODEL
# - app/deepseek_ocr.py: u≈ºyj fallback_model, zmie≈Ñ n-gram params
# - app/telegram/notifications.py: fix URL

# 3. Restart
docker-compose down && docker-compose up -d

# 4. Test
# Upload problematyczny PDF ponownie
```

### Priority Matrix

| Problem | Priorytet | Effort | Impact | Status |
|---------|-----------|--------|--------|--------|
| Brak fallback model | üî¥ P1 | 15 min | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | Ready to deploy |
| N-gram detection | üî¥ P1 | 15 min | ‚≠ê‚≠ê‚≠ê‚≠ê | Ready to deploy |
| Telegram URL | üü° P2 | 10 min | ‚≠ê‚≠ê | Ready to deploy |
| Multi-page total | üü° P2 | 1.5h | ‚≠ê‚≠ê‚≠ê‚≠ê | Needs development |
| Image preprocessing | üü¢ P3 | 1h | ‚≠ê‚≠ê‚≠ê | Optional |
| PaddleOCR cascade | üü¢ P3 | 3h | ‚≠ê‚≠ê | Optional |

***

**Research sources:**
- DeepSeek-OCR repetition fix [learnopencv](https://learnopencv.com/what-makes-deepseek-ocr-so-powerful/)
- Qwen3-VL vs Qwen2.5-VL benchmarks [reddit](https://www.reddit.com/r/LocalLLaMA/comments/1o9xf4q/experiment_qwen3vl8b_vs_qwen25vl7b_test_results/)
- Multi-page OCR best practices [skywork](https://skywork.ai/blog/llm/common-errors-in-deepseek-ocr-and-how-to-fix-them/)

Marcinnie, masz szczƒô≈õcie - **Qwen3-VL-8B ju≈º jest zainstalowany** i research pokazuje ≈ºe jest lepszy ni≈º ten kt√≥ry system pr√≥buje u≈ºyƒá. Faza 1 to dos≈Çownie 30-45 minut pracy i powinno rozwiƒÖzaƒá ~80% problemu. Chcesz ≈ºebym przygotowa≈Ç konkretne pliki do wdro≈ºenia (diff patches)?